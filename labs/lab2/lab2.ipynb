{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WB-XIC, Lab2: Wstęp do sieci neuronowych i PyTorch\n",
    "\n",
    "Wymagania: Python, NumPy, Jupyter Notebook\n",
    "\n",
    "Bazując na [Dive into Deep Learning](https://d2l.ai/index.html)\n",
    "\n",
    "PyTorch:\n",
    "- https://pytorch.org\n",
    "- https://github.com/pytorch/pytorch\n",
    "\n",
    "## Wstęp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install torch\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 1., 2., 3., 4., 5., 6., 7., 8., 9.])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# np.arange(10, dtype=np.float32)\n",
    "x = torch.arange(10, dtype=torch.float32)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.numel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1.],\n",
       "        [2., 3.],\n",
       "        [4., 5.],\n",
       "        [6., 7.],\n",
       "        [8., 9.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.reshape(5, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.reshape(5, 2).numel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros((1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.]]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.ones((2, 3, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0709,  0.1597, -0.1381, -2.0224,  0.2959])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randn(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "randint(): argument 'size' (position 2) must be tuple of ints, not int",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_29492/3181214388.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# ?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: randint(): argument 'size' (position 2) must be tuple of ints, not int"
     ]
    }
   ],
   "source": [
    "torch.randint(10, 5) # ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.\n",
    "a = torch.tensor([1, 2, 3])\n",
    "# 2.\n",
    "b = torch.from_numpy(np.array([2, 3, 4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 5, 7])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a + b "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zadanie 1.\n",
    "1. stworzyć poziomy wektor `x` z 4 unikalnymi wartościami całkowitymi\n",
    "2. stworzyć macierz `X` składającą się z wierszy: wszystkich możliwych permutacji wektora `x`\n",
    "3. stworzyć pionowy wektor `w` z 4 wartościami z rozkładu normalnego\n",
    "4. pomnożyć macierzowo `X*w`\n",
    "5. znaleźć indeksy dla maksimum i minimum wierszy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(7)\n",
    "np.random.seed(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Pochodna i różniczkowanie](https://d2l.ai/chapter_preliminaries/calculus.html#derivatives-and-differentiation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    return x ** 2 - 2 * x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numerical_lim(f, x, h):\n",
    "    return (f(x + h) - f(x)) / h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x = 1, h=1.00000, numerical limit=1.00000\n",
      "x = 1, h=0.10000, numerical limit=0.10000\n",
      "x = 1, h=0.01000, numerical limit=0.01000\n",
      "x = 1, h=0.00100, numerical limit=0.00100\n",
      "x = 1, h=0.00010, numerical limit=0.00010\n"
     ]
    }
   ],
   "source": [
    "h = 1\n",
    "for i in range(5):\n",
    "    print(f'x = {1}, h={h:.5f}, numerical limit={numerical_lim(f, 1, h):.5f}')\n",
    "    h *= 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wynik: https://www.wolframalpha.com/input?i=x+**+2+-+2+*+x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zadanie 2.\n",
    "\n",
    "`y_hat = torch.mm(X, w)` (z Zadania 1.) \n",
    "1. stworzyć pionowy wektor `y` poprzez dodanie szumu z rozkładu normalnego do `y_hat`\n",
    "2. policzyć średni błąd kwadratowy [`MSE(y, y_hat)`](https://pl.wikipedia.org/wiki/B%C5%82%C4%85d_%C5%9Bredniokwadratowy)\n",
    "3. napisać wzór na pochodną `MSE` względem `w` (teoretycznie, w markdown)\n",
    "4. policzyć pochodną `MSE` po `w`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Uwaga!** Wyraz wolny, bias - `b` -> [szczegóły](https://d2l.ai/chapter_linear-networks/linear-regression.html)\n",
    "\n",
    "## Gradient descent na przykładzie regresji liniowej\n",
    "\n",
    "### Zadanie 3.\n",
    "\n",
    "Spróbuj zaimplementować poniższy pseudokod."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "epochs = 100\n",
    "for i in range(epochs):\n",
    "    # 1. policz gradient MSE\n",
    "    # 2. zaktualizuj wagi wykorzystując gradient i learning_rate\n",
    "    pass\n",
    "# 3. policz MSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Uwaga!** Wyraz wolny, bias - `b` -> [szczegóły](https://d2l.ai/chapter_linear-networks/linear-regression.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Klasyfikacja"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Główna różnica w klasyfikacji to dodanie nowego wymiaru - klasy (np. `3` dla danych iris, `10` dla MNIST):\n",
    "1. wektor `y` w klasyfikacji binarnej ma dwa wymiary `(N, 2)`\n",
    "2. wektor `y_hat` musi być normalizowany - prawdopodobieństwa przynależności do klas sumują się do 1 wykorzystując [SoftMax](https://d2l.ai/chapter_linear-networks/softmax-regression-concise.html#softmax-implementation-revisited)\n",
    "3. stosujemy funkcję straty Cross entropy zamiast MSE; zmienia się sposób liczenia pochodnej"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(7)\n",
    "np.random.seed(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_inputs = 3\n",
    "X = np.random.normal(size=(100, num_inputs))\n",
    "y = (X.sum(axis=1) > 0).astype(np.int)\n",
    "Y = np.column_stack((y, 1- y))\n",
    "num_outputs = Y.shape[1]\n",
    "X = torch.as_tensor(X, dtype=torch.float32)\n",
    "Y = torch.as_tensor(Y, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# requires_grad - informujemy o zaalokowaniu dodatkowej pamięci na gradient\n",
    "W = torch.normal(0, 0.01, size=(num_inputs, num_outputs), requires_grad=True)\n",
    "b = torch.zeros(num_outputs, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(X):\n",
    "    X_exp = torch.exp(X)\n",
    "    partition = X_exp.sum(1, keepdim=True)\n",
    "    return X_exp / partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neural_network(X):\n",
    "    # w tym przypadku architektura odpowiada regresji logistycznej\n",
    "    return softmax(torch.mm(X.reshape((-1, W.shape[0])), W) + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy(y_hat, y):\n",
    "    return - torch.log(y_hat[range(len(y_hat)), y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD({W, b}, lr=0.001)\n",
    "errors = []\n",
    "\n",
    "for i in range(100):\n",
    "    y_hat = neural_network(X)\n",
    "    errors += [np.abs((torch.as_tensor(y) - y_hat.argmax(1)).numpy()).mean()]\n",
    "    l = cross_entropy(y_hat, y)\n",
    "    optimizer.zero_grad()\n",
    "    l.mean().backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  0,  0, -1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  1,  0,  1,  0,  0,\n",
       "         0,  0,  0,  0,  0,  1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  1,  0,\n",
       "         0,  0,  0,  0,  0, -1,  1, -1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0, -1,  0, -1,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  1,  1,  0,  0])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.as_tensor(y) - y_hat.argmax(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0154,  0.0218],\n",
       "        [-0.0107,  0.0090],\n",
       "        [-0.0087,  0.0167]], requires_grad=True)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 2.5413e-06, -2.5412e-06], requires_grad=True)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*policzyć macierz pomyłek klasyfikacji binarnej"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Praca Domowa 1\n",
    "\n",
    "Indywidualnie, zaimplementować model sieci neuronowej (MLP) do klasyfikacji w `torch` i przetestować go na dwóch zbiorach danych: XOR (wygenerować), oraz iris (pobrać). Powstały raport w formatach `.ipynb` oraz `.html` powinien zawierać wionski z przeprowadzonej analizy.\n",
    "1. do 2 punktów uzyskuje się za skuteczność klasyfikacji modeli i wizualizację procesu uczenia\n",
    "2. do 2 punktów uzyskuje się za analizę porównawczą różnych architektur sieci neuronowych (liczby neuronów i warstw)\n",
    "3. 1 punkt uzyskuje się za analizę porównawczą różnych wartości `learning_rate` \n",
    "4. 1 punkt uzyskuje się za wytrenowanie skutecznego modelu na zbiorze danych MNIST i analizę macierzy pomyłek tej klasyfikacji\n",
    "5. 1 punkt uzyskuje się za ewaluowanie powyższych zjawisk na podzbiorze treningowym i testowym (analizę zjawiska przeuczenia)\n",
    "6. 1 punkt uzyskuje się za animację zmiany granic decyzyjnych klasyfikacji podczas uczenia (na wybranym zbiorze danych)\n",
    "7. do 2 punktów uzyskuje sie za jakość raportu (opisu, wizualizacji, kodu).\n",
    "\n",
    "**Uwaga!** Warto zacząć od uczenia bardzo małych sieci i stopniowo zwiększać ich skomplikowanie.\n",
    "\n",
    "Deadline: 16 marca 23:59. Na zajęciach 17 marca 5 wybranch osób krótko zaprezentuje swoje wyniki."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6ab6057dad60620dec75a45f968cfcb183b6d526d8d16dda8af77d690bdae944"
  },
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
