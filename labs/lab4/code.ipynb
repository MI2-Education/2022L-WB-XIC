{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "code.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# WB-XIC, Lab4: WstÄ™p do konwolucyjnych sieci neuronowych"
      ],
      "metadata": {
        "id": "M9PhD6QKNZkQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python --version"
      ],
      "metadata": {
        "id": "otHuJnvE-SEo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gtjfC1WT920D"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.__version__"
      ],
      "metadata": {
        "id": "OJ81ed0w-NvN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import captum"
      ],
      "metadata": {
        "id": "CRXBz8bhHxYW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install captum"
      ],
      "metadata": {
        "id": "Jfpc-pDIH1yw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.is_available()"
      ],
      "metadata": {
        "id": "Qqq0jQau-PoG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.current_device()"
      ],
      "metadata": {
        "id": "Ba__M98y-Vor"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.device_count()"
      ],
      "metadata": {
        "id": "xBLO_-tn-Wyt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.get_device_name(0)"
      ],
      "metadata": {
        "id": "a0ryRDnI-Ym3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():  \n",
        "  DEVICE = \"cuda:0\" \n",
        "else:  \n",
        "  DEVICE = \"cpu\" "
      ],
      "metadata": {
        "id": "FeABCfLdI6WW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Example of torch + CNN + FashionMNIST\n",
        "\n",
        "**Edited the following great resource: https://towardsdatascience.com/build-a-fashion-mnist-cnn-pytorch-style-efb297e22582** \n",
        "\n",
        "**for educational purposes on the basis of \"Fair Use\".**\n",
        "\n",
        "**Kudos to [Michael Li](https://lymenlee.medium.com/).**"
      ],
      "metadata": {
        "id": "TDU_bFw7AZDR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Imports"
      ],
      "metadata": {
        "id": "L5nQWTJtILTx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import standard PyTorch modules\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.tensorboard import SummaryWriter # TensorBoard support\n",
        "\n",
        "# import torchvision module to handle image manipulation\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# calculate train time, writing train data to files etc.\n",
        "import time\n",
        "import pandas as pd\n",
        "import json\n",
        "from IPython.display import clear_output\n",
        "\n",
        "torch.set_printoptions(linewidth=120)\n",
        "torch.set_grad_enabled(True)     # On by default, leave it here for clarity"
      ],
      "metadata": {
        "id": "RQXd6eDi-Z8b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load data"
      ],
      "metadata": {
        "id": "ZNi8vV-dINYD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use standard FashionMNIST dataset\n",
        "train_set = torchvision.datasets.FashionMNIST(\n",
        "    root = './data/FashionMNIST',\n",
        "    train = True,\n",
        "    download = True,\n",
        "    transform = transforms.Compose([\n",
        "        transforms.ToTensor()                                 \n",
        "    ])\n",
        ")"
      ],
      "metadata": {
        "id": "YrcBUkFt_Ga3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define the neural network architecture"
      ],
      "metadata": {
        "id": "_HPPluEEIOZH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the neural network, expand on top of nn.Module\n",
        "class Network(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "    # define layers\n",
        "    self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5)\n",
        "    self.conv2 = nn.Conv2d(in_channels=6, out_channels=12, kernel_size=5)\n",
        "\n",
        "    self.fc1 = nn.Linear(in_features=12*4*4, out_features=120)\n",
        "    self.fc2 = nn.Linear(in_features=120, out_features=60)\n",
        "    self.out = nn.Linear(in_features=60, out_features=10)\n",
        "\n",
        "  # define forward function\n",
        "  def forward(self, t):\n",
        "    # conv 1\n",
        "    t = self.conv1(t)\n",
        "    t = F.relu(t)\n",
        "    t = F.max_pool2d(t, kernel_size=2, stride=2)\n",
        "\n",
        "    # conv 2\n",
        "    t = self.conv2(t)\n",
        "    t = F.relu(t)\n",
        "    t = F.max_pool2d(t, kernel_size=2, stride=2)\n",
        "\n",
        "    # fc1\n",
        "    t = t.reshape(-1, 12*4*4)\n",
        "    t = self.fc1(t)\n",
        "    t = F.relu(t)\n",
        "\n",
        "    # fc2\n",
        "    t = self.fc2(t)\n",
        "    t = F.relu(t)\n",
        "\n",
        "    # output\n",
        "    t = self.out(t)\n",
        "    # don't need softmax here since we'll use cross-entropy as activation.\n",
        "\n",
        "    return t"
      ],
      "metadata": {
        "id": "RDKgPBen_Ij3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Parameter grid search"
      ],
      "metadata": {
        "id": "oHK5MJDSIEOe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# put all hyper params into a OrderedDict, easily expandable\n",
        "from collections  import OrderedDict\n",
        "params = OrderedDict(\n",
        "    lr = [.01, .001],\n",
        "    batch_size = [100, 1000],\n",
        "    shuffle = [True, False]\n",
        ")\n",
        "epochs = 3"
      ],
      "metadata": {
        "id": "dpypyrOn_L4r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Exemplary boilerplate code for experiment tracking"
      ],
      "metadata": {
        "id": "XZFpzG22IayX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import modules to build RunBuilder and RunManager helper classes\n",
        "from collections import namedtuple\n",
        "from itertools import product\n",
        "\n",
        "# Read in the hyper-parameters and return a Run namedtuple containing all the \n",
        "# combinations of hyper-parameters\n",
        "class RunBuilder():\n",
        "  @staticmethod\n",
        "  def get_runs(params):\n",
        "\n",
        "    Run = namedtuple('Run', params.keys())\n",
        "\n",
        "    runs = []\n",
        "    for v in product(*params.values()):\n",
        "      runs.append(Run(*v))\n",
        "    \n",
        "    return runs\n",
        "\n",
        "# Helper class, help track loss, accuracy, epoch time, run time, \n",
        "# hyper-parameters etc. Also record to TensorBoard and write into csv, json\n",
        "class RunManager():\n",
        "  def __init__(self):\n",
        "\n",
        "    # tracking every epoch count, loss, accuracy, time\n",
        "    self.epoch_count = 0\n",
        "    self.epoch_loss = 0\n",
        "    self.epoch_num_correct = 0\n",
        "    self.epoch_start_time = None\n",
        "\n",
        "    # tracking every run count, run data, hyper-params used, time\n",
        "    self.run_params = None\n",
        "    self.run_count = 0\n",
        "    self.run_data = []\n",
        "    self.run_start_time = None\n",
        "\n",
        "    # record model, loader and TensorBoard \n",
        "    self.network = None\n",
        "    self.loader = None\n",
        "    self.tb = None\n",
        "\n",
        "  # record the count, hyper-param, model, loader of each run\n",
        "  # record sample images and network graph to TensorBoard  \n",
        "  def begin_run(self, run, network, loader):\n",
        "\n",
        "    self.run_start_time = time.time()\n",
        "\n",
        "    self.run_params = run\n",
        "    self.run_count += 1\n",
        "\n",
        "    self.network = network\n",
        "    self.loader = loader\n",
        "    self.tb = SummaryWriter(comment=f'-{run}')\n",
        "\n",
        "    images, labels = next(iter(self.loader))\n",
        "    grid = torchvision.utils.make_grid(images.to(DEVICE))\n",
        "\n",
        "    self.tb.add_image('images', grid)\n",
        "    self.tb.add_graph(self.network, images.to(DEVICE))\n",
        "\n",
        "  # when run ends, close TensorBoard, zero epoch count\n",
        "  def end_run(self):\n",
        "    self.tb.close()\n",
        "    self.epoch_count = 0\n",
        "\n",
        "  # zero epoch count, loss, accuracy, \n",
        "  def begin_epoch(self):\n",
        "    self.epoch_start_time = time.time()\n",
        "\n",
        "    self.epoch_count += 1\n",
        "    self.epoch_loss = 0\n",
        "    self.epoch_num_correct = 0\n",
        "\n",
        "  # \n",
        "  def end_epoch(self):\n",
        "    # calculate epoch duration and run duration(accumulate)\n",
        "    epoch_duration = time.time() - self.epoch_start_time\n",
        "    run_duration = time.time() - self.run_start_time\n",
        "\n",
        "    # record epoch loss and accuracy\n",
        "    loss = self.epoch_loss / len(self.loader.dataset)\n",
        "    accuracy = self.epoch_num_correct / len(self.loader.dataset)\n",
        "\n",
        "    # Record epoch loss and accuracy to TensorBoard \n",
        "    self.tb.add_scalar('Loss', loss, self.epoch_count)\n",
        "    self.tb.add_scalar('Accuracy', accuracy, self.epoch_count)\n",
        "\n",
        "    # Record params to TensorBoard\n",
        "    for name, param in self.network.named_parameters():\n",
        "      self.tb.add_histogram(name, param, self.epoch_count)\n",
        "      self.tb.add_histogram(f'{name}.grad', param.grad, self.epoch_count)\n",
        "    \n",
        "    # Write into 'results' (OrderedDict) for all run related data\n",
        "    results = OrderedDict()\n",
        "    results[\"run\"] = self.run_count\n",
        "    results[\"epoch\"] = self.epoch_count\n",
        "    results[\"loss\"] = loss\n",
        "    results[\"accuracy\"] = accuracy\n",
        "    results[\"epoch duration\"] = epoch_duration\n",
        "    results[\"run duration\"] = run_duration\n",
        "\n",
        "    # Record hyper-params into 'results'\n",
        "    for k,v in self.run_params._asdict().items(): results[k] = v\n",
        "    self.run_data.append(results)\n",
        "    df = pd.DataFrame.from_dict(self.run_data, orient = 'columns')\n",
        "\n",
        "    # display epoch information and show progress\n",
        "    clear_output(wait=True)\n",
        "    display(df)\n",
        "\n",
        "  # accumulate loss of batch into entire epoch loss\n",
        "  def track_loss(self, loss):\n",
        "    # multiply batch size so variety of batch sizes can be compared\n",
        "    self.epoch_loss += loss.item() * self.loader.batch_size\n",
        "\n",
        "  # accumulate number of corrects of batch into entire epoch num_correct\n",
        "  def track_num_correct(self, preds, labels):\n",
        "    self.epoch_num_correct += self._get_num_correct(preds, labels)\n",
        "\n",
        "  @torch.no_grad()\n",
        "  def _get_num_correct(self, preds, labels):\n",
        "    return preds.argmax(dim=1).eq(labels).sum().item()\n",
        "  \n",
        "  # save end results of all runs into csv, json for further analysis\n",
        "  def save(self, fileName):\n",
        "\n",
        "    pd.DataFrame.from_dict(\n",
        "        self.run_data, \n",
        "        orient = 'columns',\n",
        "    ).to_csv(f'{fileName}.csv')\n",
        "\n",
        "    with open(f'{fileName}.json', 'w', encoding='utf-8') as f:\n",
        "      json.dump(self.run_data, f, ensure_ascii=False, indent=4)"
      ],
      "metadata": {
        "id": "ckywp4a5_Qmy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run experiments: train & evaluate"
      ],
      "metadata": {
        "id": "BAPC26qdOhqc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "m = RunManager()\n",
        "\n",
        "# get all runs from params using RunBuilder class\n",
        "for run in RunBuilder.get_runs(params):\n",
        "\n",
        "    # if params changes, following line of code should reflect the changes too\n",
        "    network = Network().to(DEVICE)\n",
        "    loader = torch.utils.data.DataLoader(train_set, batch_size = run.batch_size)\n",
        "    optimizer = optim.Adam(network.parameters(), lr=run.lr)\n",
        "\n",
        "    m.begin_run(run, network, loader)\n",
        "    for epoch in range(epochs):\n",
        "      \n",
        "      m.begin_epoch()\n",
        "      for batch in loader:\n",
        "        \n",
        "        images = batch[0].to(DEVICE)\n",
        "        labels = batch[1].to(DEVICE)\n",
        "        preds = network(images)\n",
        "        loss = F.cross_entropy(preds, labels)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        m.track_loss(loss)\n",
        "        m.track_num_correct(preds, labels)\n",
        "\n",
        "      m.end_epoch()\n",
        "    m.end_run()\n",
        "\n",
        "# when all runs are done, save results to files\n",
        "m.save('results')"
      ],
      "metadata": {
        "id": "_zhJLR_g_rRE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Save results"
      ],
      "metadata": {
        "id": "wGdEPUVoMZqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "id": "on9cYZf8MWJ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -av './runs/' '/content/gdrive/My Drive/temp-runs'"
      ],
      "metadata": {
        "id": "aZZnZcNAMXLQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Experiment monitoring"
      ],
      "metadata": {
        "id": "9BmmfKd2AIJ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the TensorBoard notebook extension\n",
        "%load_ext tensorboard"
      ],
      "metadata": {
        "id": "b837sg9GEeM7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorboard --logdir runs"
      ],
      "metadata": {
        "id": "yLLSqkBxEgOX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# *Useful commands"
      ],
      "metadata": {
        "id": "c0gqS0uIEu8Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -c https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz -P data"
      ],
      "metadata": {
        "id": "LoI94WvsAqhD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!tar -xvzf data/cifar-10-python.tar.gz -C data"
      ],
      "metadata": {
        "id": "wlzgvhwyFY1F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir test"
      ],
      "metadata": {
        "id": "a7aXOSi4NtdS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !unzip ./data/cifar-10-python.zip"
      ],
      "metadata": {
        "id": "MHLi41ylF6qB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install shap"
      ],
      "metadata": {
        "id": "XsgBWEVjIuPs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}